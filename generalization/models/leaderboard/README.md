# Torchvision's ImageNet-1K Leaderboard 

We download and store the leaderboard from [torchvision's ImageNet-1K Leaderboard](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights) in this folder.

## Top 10 Models
<table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Weight</th>      <th>Acc@1</th>      <th>Acc@5</th>      <th>Params</th>      <th>GFLOPS</th>      <th>Recipe</th>      <th>Card</th>    </tr>  </thead>  <tbody>    <tr>      <th>105</th>      <td>ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>88.552</td>      <td>98.694</td>      <td>633.5M</td>      <td>1016.72</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_h_14.html#torchvision.models.ViT_H_14_Weights</td>    </tr>    <tr>      <th>47</th>      <td>RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>88.228</td>      <td>98.682</td>      <td>644.8M</td>      <td>374.57</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_128gf.html#torchvision.models.RegNet_Y_128GF_Weights</td>    </tr>    <tr>      <th>108</th>      <td>ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>88.064</td>      <td>98.512</td>      <td>305.2M</td>      <td>361.99</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_16.html#torchvision.models.ViT_L_16_Weights</td>    </tr>    <tr>      <th>57</th>      <td>RegNet_Y_32GF_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>86.838</td>      <td>98.362</td>      <td>145.0M</td>      <td>94.83</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_32gf.html#torchvision.models.RegNet_Y_32GF_Weights</td>    </tr>    <tr>      <th>48</th>      <td>RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_LINEAR_V1</td>      <td>86.068</td>      <td>97.844</td>      <td>644.8M</td>      <td>127.52</td>      <td>https://github.com/pytorch/vision/pull/5793</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_128gf.html#torchvision.models.RegNet_Y_128GF_Weights</td>    </tr>    <tr>      <th>51</th>      <td>RegNet_Y_16GF_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>86.012</td>      <td>98.054</td>      <td>83.6M</td>      <td>46.73</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_16gf.html#torchvision.models.RegNet_Y_16GF_Weights</td>    </tr>    <tr>      <th>18</th>      <td>EfficientNet_V2_L_Weights.IMAGENET1K_V1</td>      <td>85.808</td>      <td>97.788</td>      <td>118.5M</td>      <td>56.08</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_l.html#torchvision.models.EfficientNet_V2_L_Weights</td>    </tr>    <tr>      <th>106</th>      <td>ViT_H_14_Weights.IMAGENET1K_SWAG_LINEAR_V1</td>      <td>85.708</td>      <td>97.730</td>      <td>632.0M</td>      <td>167.29</td>      <td>https://github.com/pytorch/vision/pull/5793</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_h_14.html#torchvision.models.ViT_H_14_Weights</td>    </tr>    <tr>      <th>102</th>      <td>ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1</td>      <td>85.304</td>      <td>97.650</td>      <td>86.9M</td>      <td>55.48</td>      <td>https://github.com/facebookresearch/SWAG</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#torchvision.models.ViT_B_16_Weights</td>    </tr>    <tr>      <th>109</th>      <td>ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1</td>      <td>85.146</td>      <td>97.422</td>      <td>304.3M</td>      <td>61.55</td>      <td>https://github.com/pytorch/vision/pull/5793</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_16.html#torchvision.models.ViT_L_16_Weights</td>    </tr>  </tbody></table>

## AlexNet

<table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Weight</th>      <th>Acc@1</th>      <th>Acc@5</th>      <th>Params</th>      <th>GFLOPS</th>      <th>Recipe</th>      <th>Card</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>AlexNet_Weights.IMAGENET1K_V1</td>      <td>56.522</td>      <td>79.066</td>      <td>61.1M</td>      <td>0.71</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.alexnet.html#torchvision.models.AlexNet_Weights</td>    </tr>  </tbody></table>

## Inception
<table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Weight</th>      <th>Acc@1</th>      <th>Acc@5</th>      <th>Params</th>      <th>GFLOPS</th>      <th>Recipe</th>      <th>Card</th>    </tr>  </thead>  <tbody>    <tr>      <th>22</th>      <td>Inception_V3_Weights.IMAGENET1K_V1</td>      <td>77.294</td>      <td>93.45</td>      <td>27.2M</td>      <td>5.71</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#inception-v3</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.inception_v3.html#torchvision.models.Inception_V3_Weights</td>    </tr>  </tbody></table>

## ResNet
<table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Weight</th>      <th>Acc@1</th>      <th>Acc@5</th>      <th>Params</th>      <th>GFLOPS</th>      <th>Recipe</th>      <th>Card</th>    </tr>  </thead>  <tbody>    <tr>      <th>72</th>      <td>ResNet101_Weights.IMAGENET1K_V1</td>      <td>77.374</td>      <td>93.546</td>      <td>44.5M</td>      <td>7.80</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#resnet</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet101.html#torchvision.models.ResNet101_Weights</td>    </tr>    <tr>      <th>73</th>      <td>ResNet101_Weights.IMAGENET1K_V2</td>      <td>81.886</td>      <td>95.780</td>      <td>44.5M</td>      <td>7.80</td>      <td>https://github.com/pytorch/vision/issues/3995#new-recipe</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet101.html#torchvision.models.ResNet101_Weights</td>    </tr>    <tr>      <th>74</th>      <td>ResNet152_Weights.IMAGENET1K_V1</td>      <td>78.312</td>      <td>94.046</td>      <td>60.2M</td>      <td>11.51</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#resnet</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet152.html#torchvision.models.ResNet152_Weights</td>    </tr>    <tr>      <th>75</th>      <td>ResNet152_Weights.IMAGENET1K_V2</td>      <td>82.284</td>      <td>96.002</td>      <td>60.2M</td>      <td>11.51</td>      <td>https://github.com/pytorch/vision/issues/3995#new-recipe</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet152.html#torchvision.models.ResNet152_Weights</td>    </tr>    <tr>      <th>76</th>      <td>ResNet18_Weights.IMAGENET1K_V1</td>      <td>69.758</td>      <td>89.078</td>      <td>11.7M</td>      <td>1.81</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#resnet</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.ResNet18_Weights</td>    </tr>    <tr>      <th>77</th>      <td>ResNet34_Weights.IMAGENET1K_V1</td>      <td>73.314</td>      <td>91.420</td>      <td>21.8M</td>      <td>3.66</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#resnet</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet34.html#torchvision.models.ResNet34_Weights</td>    </tr>    <tr>      <th>78</th>      <td>ResNet50_Weights.IMAGENET1K_V1</td>      <td>76.130</td>      <td>92.862</td>      <td>25.6M</td>      <td>4.09</td>      <td>https://github.com/pytorch/vision/tree/main/references/classification#resnet</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights</td>    </tr>    <tr>      <th>79</th>      <td>ResNet50_Weights.IMAGENET1K_V2</td>      <td>80.858</td>      <td>95.434</td>      <td>25.6M</td>      <td>4.09</td>      <td>https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights</td>    </tr>    <tr>      <th>111</th>      <td>Wide_ResNet101_2_Weights.IMAGENET1K_V1</td>      <td>78.848</td>      <td>94.284</td>      <td>126.9M</td>      <td>22.75</td>      <td>https://github.com/pytorch/vision/pull/912#issue-445437439</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet101_2.html#torchvision.models.Wide_ResNet101_2_Weights</td>    </tr>    <tr>      <th>112</th>      <td>Wide_ResNet101_2_Weights.IMAGENET1K_V2</td>      <td>82.510</td>      <td>96.020</td>      <td>126.9M</td>      <td>22.75</td>      <td>https://github.com/pytorch/vision/issues/3995#new-recipe</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet101_2.html#torchvision.models.Wide_ResNet101_2_Weights</td>    </tr>    <tr>      <th>113</th>      <td>Wide_ResNet50_2_Weights.IMAGENET1K_V1</td>      <td>78.468</td>      <td>94.086</td>      <td>68.9M</td>      <td>11.40</td>      <td>https://github.com/pytorch/vision/pull/912#issue-445437439</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet50_2.html#torchvision.models.Wide_ResNet50_2_Weights</td>    </tr>    <tr>      <th>114</th>      <td>Wide_ResNet50_2_Weights.IMAGENET1K_V2</td>      <td>81.602</td>      <td>95.758</td>      <td>68.9M</td>      <td>11.40</td>      <td>https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres</td>      <td>https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet50_2.html#torchvision.models.Wide_ResNet50_2_Weights</td>    </tr>  </tbody></table>

## Usage

* Download
```python
python imagenet.py --download
```

* Filter by model
```python
python imagenet.py --filter "resnet50"
```

* Show Top 10
```python
python imagenet.py --top 10
```
