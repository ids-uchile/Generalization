Weight,Acc@1,Acc@5,Params,GFLOPS,Recipe,Card
AlexNet_Weights.IMAGENET1K_V1,56.522,79.066,61.1M,0.71,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.alexnet.html#torchvision.models.AlexNet_Weights
ConvNeXt_Base_Weights.IMAGENET1K_V1,84.062,96.87,88.6M,15.36,https://github.com/pytorch/vision/tree/main/references/classification#convnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.convnext_base.html#torchvision.models.ConvNeXt_Base_Weights
ConvNeXt_Large_Weights.IMAGENET1K_V1,84.414,96.976,197.8M,34.36,https://github.com/pytorch/vision/tree/main/references/classification#convnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.convnext_large.html#torchvision.models.ConvNeXt_Large_Weights
ConvNeXt_Small_Weights.IMAGENET1K_V1,83.616,96.65,50.2M,8.68,https://github.com/pytorch/vision/tree/main/references/classification#convnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.convnext_small.html#torchvision.models.ConvNeXt_Small_Weights
ConvNeXt_Tiny_Weights.IMAGENET1K_V1,82.52,96.146,28.6M,4.46,https://github.com/pytorch/vision/tree/main/references/classification#convnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.convnext_tiny.html#torchvision.models.ConvNeXt_Tiny_Weights
DenseNet121_Weights.IMAGENET1K_V1,74.434,91.972,8.0M,2.83,https://github.com/pytorch/vision/pull/116,https://pytorch.org/vision/stable/models/generated/torchvision.models.densenet121.html#torchvision.models.DenseNet121_Weights
DenseNet161_Weights.IMAGENET1K_V1,77.138,93.56,28.7M,7.73,https://github.com/pytorch/vision/pull/116,https://pytorch.org/vision/stable/models/generated/torchvision.models.densenet161.html#torchvision.models.DenseNet161_Weights
DenseNet169_Weights.IMAGENET1K_V1,75.6,92.806,14.1M,3.36,https://github.com/pytorch/vision/pull/116,https://pytorch.org/vision/stable/models/generated/torchvision.models.densenet169.html#torchvision.models.DenseNet169_Weights
DenseNet201_Weights.IMAGENET1K_V1,76.896,93.37,20.0M,4.29,https://github.com/pytorch/vision/pull/116,https://pytorch.org/vision/stable/models/generated/torchvision.models.densenet201.html#torchvision.models.DenseNet201_Weights
EfficientNet_B0_Weights.IMAGENET1K_V1,77.692,93.532,5.3M,0.39,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b0.html#torchvision.models.EfficientNet_B0_Weights
EfficientNet_B1_Weights.IMAGENET1K_V1,78.642,94.186,7.8M,0.69,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b1.html#torchvision.models.EfficientNet_B1_Weights
EfficientNet_B1_Weights.IMAGENET1K_V2,79.838,94.934,7.8M,0.69,https://github.com/pytorch/vision/issues/3995#new-recipe-with-lr-wd-crop-tuning,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b1.html#torchvision.models.EfficientNet_B1_Weights
EfficientNet_B2_Weights.IMAGENET1K_V1,80.608,95.31,9.1M,1.09,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights
EfficientNet_B3_Weights.IMAGENET1K_V1,82.008,96.054,12.2M,1.83,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b3.html#torchvision.models.EfficientNet_B3_Weights
EfficientNet_B4_Weights.IMAGENET1K_V1,83.384,96.594,19.3M,4.39,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b4.html#torchvision.models.EfficientNet_B4_Weights
EfficientNet_B5_Weights.IMAGENET1K_V1,83.444,96.628,30.4M,10.27,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b5.html#torchvision.models.EfficientNet_B5_Weights
EfficientNet_B6_Weights.IMAGENET1K_V1,84.008,96.916,43.0M,19.07,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b6.html#torchvision.models.EfficientNet_B6_Weights
EfficientNet_B7_Weights.IMAGENET1K_V1,84.122,96.908,66.3M,37.75,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b7.html#torchvision.models.EfficientNet_B7_Weights
EfficientNet_V2_L_Weights.IMAGENET1K_V1,85.808,97.788,118.5M,56.08,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_l.html#torchvision.models.EfficientNet_V2_L_Weights
EfficientNet_V2_M_Weights.IMAGENET1K_V1,85.112,97.156,54.1M,24.58,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_m.html#torchvision.models.EfficientNet_V2_M_Weights
EfficientNet_V2_S_Weights.IMAGENET1K_V1,84.228,96.878,21.5M,8.37,https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_s.html#torchvision.models.EfficientNet_V2_S_Weights
GoogLeNet_Weights.IMAGENET1K_V1,69.778,89.53,6.6M,1.5,https://github.com/pytorch/vision/tree/main/references/classification#googlenet,https://pytorch.org/vision/stable/models/generated/torchvision.models.googlenet.html#torchvision.models.GoogLeNet_Weights
Inception_V3_Weights.IMAGENET1K_V1,77.294,93.45,27.2M,5.71,https://github.com/pytorch/vision/tree/main/references/classification#inception-v3,https://pytorch.org/vision/stable/models/generated/torchvision.models.inception_v3.html#torchvision.models.Inception_V3_Weights
MNASNet0_5_Weights.IMAGENET1K_V1,67.734,87.49,2.2M,0.1,https://github.com/1e100/mnasnet_trainer,https://pytorch.org/vision/stable/models/generated/torchvision.models.mnasnet0_5.html#torchvision.models.MNASNet0_5_Weights
MNASNet0_75_Weights.IMAGENET1K_V1,71.18,90.496,3.2M,0.21,https://github.com/pytorch/vision/pull/6019,https://pytorch.org/vision/stable/models/generated/torchvision.models.mnasnet0_75.html#torchvision.models.MNASNet0_75_Weights
MNASNet1_0_Weights.IMAGENET1K_V1,73.456,91.51,4.4M,0.31,https://github.com/1e100/mnasnet_trainer,https://pytorch.org/vision/stable/models/generated/torchvision.models.mnasnet1_0.html#torchvision.models.MNASNet1_0_Weights
MNASNet1_3_Weights.IMAGENET1K_V1,76.506,93.522,6.3M,0.53,https://github.com/pytorch/vision/pull/6019,https://pytorch.org/vision/stable/models/generated/torchvision.models.mnasnet1_3.html#torchvision.models.MNASNet1_3_Weights
MaxVit_T_Weights.IMAGENET1K_V1,83.7,96.722,30.9M,5.56,https://github.com/pytorch/vision/tree/main/references/classification#maxvit,https://pytorch.org/vision/stable/models/generated/torchvision.models.maxvit_t.html#torchvision.models.MaxVit_T_Weights
MobileNet_V2_Weights.IMAGENET1K_V1,71.878,90.286,3.5M,0.3,https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv2,https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.MobileNet_V2_Weights
MobileNet_V2_Weights.IMAGENET1K_V2,72.154,90.822,3.5M,0.3,https://github.com/pytorch/vision/issues/3995#new-recipe-with-reg-tuning,https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.MobileNet_V2_Weights
MobileNet_V3_Large_Weights.IMAGENET1K_V1,74.042,91.34,5.5M,0.22,https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small,https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v3_large.html#torchvision.models.MobileNet_V3_Large_Weights
MobileNet_V3_Large_Weights.IMAGENET1K_V2,75.274,92.566,5.5M,0.22,https://github.com/pytorch/vision/issues/3995#new-recipe-with-reg-tuning,https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v3_large.html#torchvision.models.MobileNet_V3_Large_Weights
MobileNet_V3_Small_Weights.IMAGENET1K_V1,67.668,87.402,2.5M,0.06,https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small,https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v3_small.html#torchvision.models.MobileNet_V3_Small_Weights
RegNet_X_16GF_Weights.IMAGENET1K_V1,80.058,94.944,54.3M,15.94,https://github.com/pytorch/vision/tree/main/references/classification#medium-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_16gf.html#torchvision.models.RegNet_X_16GF_Weights
RegNet_X_16GF_Weights.IMAGENET1K_V2,82.716,96.196,54.3M,15.94,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_16gf.html#torchvision.models.RegNet_X_16GF_Weights
RegNet_X_1_6GF_Weights.IMAGENET1K_V1,77.04,93.44,9.2M,1.6,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_1_6gf.html#torchvision.models.RegNet_X_1_6GF_Weights
RegNet_X_1_6GF_Weights.IMAGENET1K_V2,79.668,94.922,9.2M,1.6,https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_1_6gf.html#torchvision.models.RegNet_X_1_6GF_Weights
RegNet_X_32GF_Weights.IMAGENET1K_V1,80.622,95.248,107.8M,31.74,https://github.com/pytorch/vision/tree/main/references/classification#large-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_32gf.html#torchvision.models.RegNet_X_32GF_Weights
RegNet_X_32GF_Weights.IMAGENET1K_V2,83.014,96.288,107.8M,31.74,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_32gf.html#torchvision.models.RegNet_X_32GF_Weights
RegNet_X_3_2GF_Weights.IMAGENET1K_V1,78.364,93.992,15.3M,3.18,https://github.com/pytorch/vision/tree/main/references/classification#medium-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_3_2gf.html#torchvision.models.RegNet_X_3_2GF_Weights
RegNet_X_3_2GF_Weights.IMAGENET1K_V2,81.196,95.43,15.3M,3.18,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_3_2gf.html#torchvision.models.RegNet_X_3_2GF_Weights
RegNet_X_400MF_Weights.IMAGENET1K_V1,72.834,90.95,5.5M,0.41,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_400mf.html#torchvision.models.RegNet_X_400MF_Weights
RegNet_X_400MF_Weights.IMAGENET1K_V2,74.864,92.322,5.5M,0.41,https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_400mf.html#torchvision.models.RegNet_X_400MF_Weights
RegNet_X_800MF_Weights.IMAGENET1K_V1,75.212,92.348,7.3M,0.8,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_800mf.html#torchvision.models.RegNet_X_800MF_Weights
RegNet_X_800MF_Weights.IMAGENET1K_V2,77.522,93.826,7.3M,0.8,https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_800mf.html#torchvision.models.RegNet_X_800MF_Weights
RegNet_X_8GF_Weights.IMAGENET1K_V1,79.344,94.686,39.6M,8,https://github.com/pytorch/vision/tree/main/references/classification#medium-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_8gf.html#torchvision.models.RegNet_X_8GF_Weights
RegNet_X_8GF_Weights.IMAGENET1K_V2,81.682,95.678,39.6M,8,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_8gf.html#torchvision.models.RegNet_X_8GF_Weights
RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_E2E_V1,88.228,98.682,644.8M,374.57,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_128gf.html#torchvision.models.RegNet_Y_128GF_Weights
RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_LINEAR_V1,86.068,97.844,644.8M,127.52,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_128gf.html#torchvision.models.RegNet_Y_128GF_Weights
RegNet_Y_16GF_Weights.IMAGENET1K_V1,80.424,95.24,83.6M,15.91,https://github.com/pytorch/vision/tree/main/references/classification#large-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_16gf.html#torchvision.models.RegNet_Y_16GF_Weights
RegNet_Y_16GF_Weights.IMAGENET1K_V2,82.886,96.328,83.6M,15.91,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_16gf.html#torchvision.models.RegNet_Y_16GF_Weights
RegNet_Y_16GF_Weights.IMAGENET1K_SWAG_E2E_V1,86.012,98.054,83.6M,46.73,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_16gf.html#torchvision.models.RegNet_Y_16GF_Weights
RegNet_Y_16GF_Weights.IMAGENET1K_SWAG_LINEAR_V1,83.976,97.244,83.6M,15.91,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_16gf.html#torchvision.models.RegNet_Y_16GF_Weights
RegNet_Y_1_6GF_Weights.IMAGENET1K_V1,77.95,93.966,11.2M,1.61,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_1_6gf.html#torchvision.models.RegNet_Y_1_6GF_Weights
RegNet_Y_1_6GF_Weights.IMAGENET1K_V2,80.876,95.444,11.2M,1.61,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_1_6gf.html#torchvision.models.RegNet_Y_1_6GF_Weights
RegNet_Y_32GF_Weights.IMAGENET1K_V1,80.878,95.34,145.0M,32.28,https://github.com/pytorch/vision/tree/main/references/classification#large-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_32gf.html#torchvision.models.RegNet_Y_32GF_Weights
RegNet_Y_32GF_Weights.IMAGENET1K_V2,83.368,96.498,145.0M,32.28,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_32gf.html#torchvision.models.RegNet_Y_32GF_Weights
RegNet_Y_32GF_Weights.IMAGENET1K_SWAG_E2E_V1,86.838,98.362,145.0M,94.83,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_32gf.html#torchvision.models.RegNet_Y_32GF_Weights
RegNet_Y_32GF_Weights.IMAGENET1K_SWAG_LINEAR_V1,84.622,97.48,145.0M,32.28,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_32gf.html#torchvision.models.RegNet_Y_32GF_Weights
RegNet_Y_3_2GF_Weights.IMAGENET1K_V1,78.948,94.576,19.4M,3.18,https://github.com/pytorch/vision/tree/main/references/classification#medium-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_3_2gf.html#torchvision.models.RegNet_Y_3_2GF_Weights
RegNet_Y_3_2GF_Weights.IMAGENET1K_V2,81.982,95.972,19.4M,3.18,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_3_2gf.html#torchvision.models.RegNet_Y_3_2GF_Weights
RegNet_Y_400MF_Weights.IMAGENET1K_V1,74.046,91.716,4.3M,0.4,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_400mf.html#torchvision.models.RegNet_Y_400MF_Weights
RegNet_Y_400MF_Weights.IMAGENET1K_V2,75.804,92.742,4.3M,0.4,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_400mf.html#torchvision.models.RegNet_Y_400MF_Weights
RegNet_Y_800MF_Weights.IMAGENET1K_V1,76.42,93.136,6.4M,0.83,https://github.com/pytorch/vision/tree/main/references/classification#small-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_800mf.html#torchvision.models.RegNet_Y_800MF_Weights
RegNet_Y_800MF_Weights.IMAGENET1K_V2,78.828,94.502,6.4M,0.83,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_800mf.html#torchvision.models.RegNet_Y_800MF_Weights
RegNet_Y_8GF_Weights.IMAGENET1K_V1,80.032,95.048,39.4M,8.47,https://github.com/pytorch/vision/tree/main/references/classification#medium-models,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_8gf.html#torchvision.models.RegNet_Y_8GF_Weights
RegNet_Y_8GF_Weights.IMAGENET1K_V2,82.828,96.33,39.4M,8.47,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_y_8gf.html#torchvision.models.RegNet_Y_8GF_Weights
ResNeXt101_32X8D_Weights.IMAGENET1K_V1,79.312,94.526,88.8M,16.41,https://github.com/pytorch/vision/tree/main/references/classification#resnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnext101_32x8d.html#torchvision.models.ResNeXt101_32X8D_Weights
ResNeXt101_32X8D_Weights.IMAGENET1K_V2,82.834,96.228,88.8M,16.41,https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnext101_32x8d.html#torchvision.models.ResNeXt101_32X8D_Weights
ResNeXt101_64X4D_Weights.IMAGENET1K_V1,83.246,96.454,83.5M,15.46,https://github.com/pytorch/vision/pull/5935,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnext101_64x4d.html#torchvision.models.ResNeXt101_64X4D_Weights
ResNeXt50_32X4D_Weights.IMAGENET1K_V1,77.618,93.698,25.0M,4.23,https://github.com/pytorch/vision/tree/main/references/classification#resnext,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnext50_32x4d.html#torchvision.models.ResNeXt50_32X4D_Weights
ResNeXt50_32X4D_Weights.IMAGENET1K_V2,81.198,95.34,25.0M,4.23,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnext50_32x4d.html#torchvision.models.ResNeXt50_32X4D_Weights
ResNet101_Weights.IMAGENET1K_V1,77.374,93.546,44.5M,7.8,https://github.com/pytorch/vision/tree/main/references/classification#resnet,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet101.html#torchvision.models.ResNet101_Weights
ResNet101_Weights.IMAGENET1K_V2,81.886,95.78,44.5M,7.8,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet101.html#torchvision.models.ResNet101_Weights
ResNet152_Weights.IMAGENET1K_V1,78.312,94.046,60.2M,11.51,https://github.com/pytorch/vision/tree/main/references/classification#resnet,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet152.html#torchvision.models.ResNet152_Weights
ResNet152_Weights.IMAGENET1K_V2,82.284,96.002,60.2M,11.51,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet152.html#torchvision.models.ResNet152_Weights
ResNet18_Weights.IMAGENET1K_V1,69.758,89.078,11.7M,1.81,https://github.com/pytorch/vision/tree/main/references/classification#resnet,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.ResNet18_Weights
ResNet34_Weights.IMAGENET1K_V1,73.314,91.42,21.8M,3.66,https://github.com/pytorch/vision/tree/main/references/classification#resnet,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet34.html#torchvision.models.ResNet34_Weights
ResNet50_Weights.IMAGENET1K_V1,76.13,92.862,25.6M,4.09,https://github.com/pytorch/vision/tree/main/references/classification#resnet,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights
ResNet50_Weights.IMAGENET1K_V2,80.858,95.434,25.6M,4.09,https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621,https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights
ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1,60.552,81.746,1.4M,0.04,https://github.com/ericsun99/Shufflenet-v2-Pytorch,https://pytorch.org/vision/stable/models/generated/torchvision.models.shufflenet_v2_x0_5.html#torchvision.models.ShuffleNet_V2_X0_5_Weights
ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1,69.362,88.316,2.3M,0.14,https://github.com/ericsun99/Shufflenet-v2-Pytorch,https://pytorch.org/vision/stable/models/generated/torchvision.models.shufflenet_v2_x1_0.html#torchvision.models.ShuffleNet_V2_X1_0_Weights
ShuffleNet_V2_X1_5_Weights.IMAGENET1K_V1,72.996,91.086,3.5M,0.3,https://github.com/pytorch/vision/pull/5906,https://pytorch.org/vision/stable/models/generated/torchvision.models.shufflenet_v2_x1_5.html#torchvision.models.ShuffleNet_V2_X1_5_Weights
ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1,76.23,93.006,7.4M,0.58,https://github.com/pytorch/vision/pull/5906,https://pytorch.org/vision/stable/models/generated/torchvision.models.shufflenet_v2_x2_0.html#torchvision.models.ShuffleNet_V2_X2_0_Weights
SqueezeNet1_0_Weights.IMAGENET1K_V1,58.092,80.42,1.2M,0.82,https://github.com/pytorch/vision/pull/49#issuecomment-277560717,https://pytorch.org/vision/stable/models/generated/torchvision.models.squeezenet1_0.html#torchvision.models.SqueezeNet1_0_Weights
SqueezeNet1_1_Weights.IMAGENET1K_V1,58.178,80.624,1.2M,0.35,https://github.com/pytorch/vision/pull/49#issuecomment-277560717,https://pytorch.org/vision/stable/models/generated/torchvision.models.squeezenet1_1.html#torchvision.models.SqueezeNet1_1_Weights
Swin_B_Weights.IMAGENET1K_V1,83.582,96.64,87.8M,15.43,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_b.html#torchvision.models.Swin_B_Weights
Swin_S_Weights.IMAGENET1K_V1,83.196,96.36,49.6M,8.74,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_s.html#torchvision.models.Swin_S_Weights
Swin_T_Weights.IMAGENET1K_V1,81.474,95.776,28.3M,4.49,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_t.html#torchvision.models.Swin_T_Weights
Swin_V2_B_Weights.IMAGENET1K_V1,84.112,96.864,87.9M,20.32,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_v2_b.html#torchvision.models.Swin_V2_B_Weights
Swin_V2_S_Weights.IMAGENET1K_V1,83.712,96.816,49.7M,11.55,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_v2_s.html#torchvision.models.Swin_V2_S_Weights
Swin_V2_T_Weights.IMAGENET1K_V1,82.072,96.132,28.4M,5.94,https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2,https://pytorch.org/vision/stable/models/generated/torchvision.models.swin_v2_t.html#torchvision.models.Swin_V2_T_Weights
VGG11_BN_Weights.IMAGENET1K_V1,70.37,89.81,132.9M,7.61,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg11_bn.html#torchvision.models.VGG11_BN_Weights
VGG11_Weights.IMAGENET1K_V1,69.02,88.628,132.9M,7.61,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg11.html#torchvision.models.VGG11_Weights
VGG13_BN_Weights.IMAGENET1K_V1,71.586,90.374,133.1M,11.31,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg13_bn.html#torchvision.models.VGG13_BN_Weights
VGG13_Weights.IMAGENET1K_V1,69.928,89.246,133.0M,11.31,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg13.html#torchvision.models.VGG13_Weights
VGG16_BN_Weights.IMAGENET1K_V1,73.36,91.516,138.4M,15.47,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16_bn.html#torchvision.models.VGG16_BN_Weights
VGG16_Weights.IMAGENET1K_V1,71.592,90.382,138.4M,15.47,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.VGG16_Weights
VGG16_Weights.IMAGENET1K_FEATURES,nan,nan,138.4M,15.47,https://github.com/amdegroot/ssd.pytorch#training-ssd,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.VGG16_Weights
VGG19_BN_Weights.IMAGENET1K_V1,74.218,91.842,143.7M,19.63,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg19_bn.html#torchvision.models.VGG19_BN_Weights
VGG19_Weights.IMAGENET1K_V1,72.376,90.876,143.7M,19.63,https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg,https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg19.html#torchvision.models.VGG19_Weights
ViT_B_16_Weights.IMAGENET1K_V1,81.072,95.318,86.6M,17.56,https://github.com/pytorch/vision/tree/main/references/classification#vit_b_16,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#torchvision.models.ViT_B_16_Weights
ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1,85.304,97.65,86.9M,55.48,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#torchvision.models.ViT_B_16_Weights
ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1,81.886,96.18,86.6M,17.56,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#torchvision.models.ViT_B_16_Weights
ViT_B_32_Weights.IMAGENET1K_V1,75.912,92.466,88.2M,4.41,https://github.com/pytorch/vision/tree/main/references/classification#vit_b_32,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_32.html#torchvision.models.ViT_B_32_Weights
ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1,88.552,98.694,633.5M,1016.72,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_h_14.html#torchvision.models.ViT_H_14_Weights
ViT_H_14_Weights.IMAGENET1K_SWAG_LINEAR_V1,85.708,97.73,632.0M,167.29,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_h_14.html#torchvision.models.ViT_H_14_Weights
ViT_L_16_Weights.IMAGENET1K_V1,79.662,94.638,304.3M,61.55,https://github.com/pytorch/vision/tree/main/references/classification#vit_l_16,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_16.html#torchvision.models.ViT_L_16_Weights
ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1,88.064,98.512,305.2M,361.99,https://github.com/facebookresearch/SWAG,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_16.html#torchvision.models.ViT_L_16_Weights
ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1,85.146,97.422,304.3M,61.55,https://github.com/pytorch/vision/pull/5793,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_16.html#torchvision.models.ViT_L_16_Weights
ViT_L_32_Weights.IMAGENET1K_V1,76.972,93.07,306.5M,15.38,https://github.com/pytorch/vision/tree/main/references/classification#vit_l_32,https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_l_32.html#torchvision.models.ViT_L_32_Weights
Wide_ResNet101_2_Weights.IMAGENET1K_V1,78.848,94.284,126.9M,22.75,https://github.com/pytorch/vision/pull/912#issue-445437439,https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet101_2.html#torchvision.models.Wide_ResNet101_2_Weights
Wide_ResNet101_2_Weights.IMAGENET1K_V2,82.51,96.02,126.9M,22.75,https://github.com/pytorch/vision/issues/3995#new-recipe,https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet101_2.html#torchvision.models.Wide_ResNet101_2_Weights
Wide_ResNet50_2_Weights.IMAGENET1K_V1,78.468,94.086,68.9M,11.4,https://github.com/pytorch/vision/pull/912#issue-445437439,https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet50_2.html#torchvision.models.Wide_ResNet50_2_Weights
Wide_ResNet50_2_Weights.IMAGENET1K_V2,81.602,95.758,68.9M,11.4,https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres,https://pytorch.org/vision/stable/models/generated/torchvision.models.wide_resnet50_2.html#torchvision.models.Wide_ResNet50_2_Weights
