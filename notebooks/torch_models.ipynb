{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available corruptions:\n",
      " ['gaussian_pixels', 'random_labels', 'random_pixels', 'partial_labels', 'shuffled_pixels']\n"
     ]
    }
   ],
   "source": [
    "from generalization.randomization import available_corruptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_num_cpus():\n",
    "    return len(os.sched_getaffinity(0))\n",
    "\n",
    "\n",
    "def check(learn, dl, plt_title=None):\n",
    "    y_pred, ys, losses = learn.get_preds(1, dl=dl, with_loss=True, reorder=True)\n",
    "\n",
    "    print(y_pred[0].min(), y_pred[0].max(), y_pred[0].sum())\n",
    "    print(y_pred[0].argmax(), ys[0], losses[0])\n",
    "    plot_losses(losses, width=1, plt_title=plt_title)\n",
    "\n",
    "\n",
    "def plot_losses(losses, width=1, plt_title=None):\n",
    "    plt.bar(np.arange(len(losses)), losses, width=width)\n",
    "    plt.title(plt_title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Available corruptions:\\n\", available_corruptions())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generalization.randomization import build_cifar10\n",
    "import torch\n",
    "\n",
    "\n",
    "def build_experiments(corrupt_prob, corrupt_name=None, batch_size=128):\n",
    "    corruptions = available_corruptions()\n",
    "\n",
    "    experiments = dict()\n",
    "\n",
    "    if corrupt_name is not None:\n",
    "        corruptions = [corrupt_name]\n",
    "\n",
    "    for corrupt_name in corruptions:\n",
    "        if corrupt_name == \"gaussian_pixels\":\n",
    "            continue\n",
    "        train_set, test_set = build_cifar10(\n",
    "            corruption_name=corrupt_name,\n",
    "            corruption_prob=corrupt_prob,\n",
    "            show_images=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=get_num_cpus(),\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        val_set, test_set = torch.utils.data.random_split(\n",
    "            test_set, [len(test_set) // 2, len(test_set) - len(test_set) // 2]\n",
    "        )\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=batch_size * 2,\n",
    "            shuffle=False,\n",
    "            num_workers=get_num_cpus(),\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=batch_size * 2,\n",
    "            shuffle=False,\n",
    "            num_workers=get_num_cpus(),\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        experiments[corrupt_name] = {\n",
    "            \"train_set\": train_set,\n",
    "            \"val_set\": val_set,\n",
    "            \"test_set\": test_set,\n",
    "            \"train_loader\": train_loader,\n",
    "            \"val_loader\": val_loader,\n",
    "            \"test_loader\": test_loader,\n",
    "        }\n",
    "    return experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, net: nn.Module, lr: float = 1e-3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.valid_top5_acc = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=n_classes, top_k=5\n",
    "        )\n",
    "        self.early_stop_counter = 0\n",
    "        self.patience = 5\n",
    "        self.best_valid_acc = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        self.log(\"train/loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.step_metrics(logits=logits, y=y, mode=\"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        self.log(\"valid/loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.step_metrics(logits=logits, y=y, mode=\"val\")\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        current_valid_acc = self.valid_acc.compute()\n",
    "        if current_valid_acc > self.best_valid_acc:\n",
    "            self.best_valid_acc = current_valid_acc\n",
    "            self.early_stop_counter = 0\n",
    "        else:\n",
    "            self.early_stop_counter += 1\n",
    "            if self.early_stop_counter > self.patience:\n",
    "                self.early_stop_counter = 0\n",
    "                # self.trainer.should_stop = True\n",
    "\n",
    "                self.logger.experiment.add_scalar(\"early_stop\", self.current_epoch)\n",
    "        \n",
    "\n",
    "    def step_metrics(self, logits, y, mode):\n",
    "        if mode == \"train\":\n",
    "            self.train_acc.update(logits, y)\n",
    "            self.log(\n",
    "                \"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True\n",
    "            )\n",
    "\n",
    "        elif mode == \"val\":\n",
    "            self.valid_acc.update(logits, y)\n",
    "            self.valid_top5_acc.update(logits, y)\n",
    "\n",
    "            self.log(\n",
    "                \"valid/acc\",\n",
    "                self.valid_acc.compute(),\n",
    "                on_step=False,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            self.log(\n",
    "                \"valid/top5_acc\",\n",
    "                self.valid_top5_acc.compute(),\n",
    "                on_step=False,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "            )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.net.parameters(), lr=self.lr, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/Code/projects/ids-generalization/notebooks/generalization/randomization/dataset.py:203: UserWarning: corruption_prob is ignored when corruption_name is 'random_*'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "dict_keys(['alexnet', 'inception', 'mlp_1x512', 'mlp_3x512'])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from generalization.models import get_cifar_models\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "SEED = 5678\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.01\n",
    "PRINT_EVERY = 3\n",
    "EPOCHS = 10\n",
    "MODEL_NAME = \"inception\"\n",
    "CORRUPT_NAME = \"random_labels\"\n",
    "\n",
    "L.seed_everything(SEED)\n",
    "experiments = build_experiments(corrupt_prob=0.1, corrupt_name=CORRUPT_NAME, batch_size=BATCH_SIZE)\n",
    "\n",
    "models = get_cifar_models(lib=\"torch\")\n",
    "print(models.keys())\n",
    "net = models.get(MODEL_NAME)\n",
    "\n",
    "logger = None\n",
    "# logger = WandbLogger(\n",
    "#     name=f\"{model}\",\n",
    "#     project=\"generalization\",\n",
    "#     log_model=True,\n",
    "#     save_dir=\"logs\",\n",
    "#     group=f\"{corruption}\"\n",
    "# )\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"logs\",\n",
    "    name=f\"{MODEL_NAME}\",\n",
    "    version=f\"{CORRUPT_NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | net            | InceptionSmall     | 8.0 M \n",
      "1 | train_acc      | MulticlassAccuracy | 0     \n",
      "2 | valid_acc      | MulticlassAccuracy | 0     \n",
      "3 | valid_top5_acc | MulticlassAccuracy | 0     \n",
      "------------------------------------------------------\n",
      "8.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.0 M     Total params\n",
      "32.191    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 0/196 [00:00<?, ?it/s, v_num=bels, valid/loss=18.10, valid/acc=0.0939, valid/top5_acc=0.443, train/loss=0.0805, train/acc=0.972]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  18%|█▊        | 35/196 [00:02<00:10, 15.51it/s, v_num=bels, valid/loss=18.10, valid/acc=0.0939, valid/top5_acc=0.443, train/loss=0.0805, train/acc=0.972]"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=60, \n",
    "    logger=logger , \n",
    "    default_root_dir=\"logs\",\n",
    ")\n",
    "pl_model = LitModel(net, lr=LEARNING_RATE, n_classes=10)\n",
    "start_time = time.time()\n",
    "trainer.fit(\n",
    "    pl_model,\n",
    "    experiments[CORRUPT_NAME][\"train_loader\"],\n",
    "    experiments[CORRUPT_NAME][\"val_loader\"],\n",
    ")\n",
    "print(f\"Training took {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from generalization.randomization.utils import CIFAR10_NORMALIZE_MEAN, CIFAR10_NORMALIZE_STD\n",
    "\n",
    "\n",
    "idx = np.random.randint(len(experiments[CORRUPT_NAME][\"train_set\"]))\n",
    "\n",
    "unnormalize = transforms.functional.normalize(\n",
    "    experiments[CORRUPT_NAME][\"train_set\"][idx][0],\n",
    "    mean=[-m / s for m, s in zip(CIFAR10_NORMALIZE_MEAN, CIFAR10_NORMALIZE_STD)],\n",
    "    std=[1 / s for s in CIFAR10_NORMALIZE_STD],\n",
    ")\n",
    "\n",
    "label = experiments[CORRUPT_NAME][\"train_set\"][idx][1]\n",
    "class_name = experiments[CORRUPT_NAME][\"train_set\"].classes[label]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "ax.imshow(unnormalize.permute(1, 2, 0))\n",
    "ax.set_title(f\"Corrupted label: {class_name}\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# \n",
    "# for model in models.keys():\n",
    "#     print(\"Model:\", model)\n",
    "\n",
    "#     for corruption, exp in experiments.items():\n",
    "#         wandb.finish()\n",
    "#         print(\"Corruption:\", corruption)\n",
    "\n",
    "#         net = models.get(model)\n",
    "#         logger = WandbLogger(\n",
    "#             name=f\"{model}\",\n",
    "#             project=\"generalization\",\n",
    "#             log_model=True,\n",
    "#             save_dir=\"logs\",\n",
    "#             group=f\"{corruption}\"\n",
    "#         )\n",
    "#         trainer = L.Trainer(max_epochs=10, logger=logger, default_root_dir=\"logs\")\n",
    "#         pl_model = LitModel(net)\n",
    "#         start_time = time.time()\n",
    "#         trainer.fit(\n",
    "#             pl_model,\n",
    "#             experiments[corruption][\"train_loader\"],\n",
    "#             experiments[corruption][\"test_loader\"],\n",
    "#         )\n",
    "#         print(\n",
    "#             f\"== Total time: {time.time() - start_time:.3f} s, {(time.time() - start_time)/ 60:.3f} min\"\n",
    "#         )\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
